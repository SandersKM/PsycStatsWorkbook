library(dplyr)
library(Ecdat)
library(flextable)
# First, we will save the data as a variable in RStudio
data("Mathlevel")
# Let's learn what kind of data this is
?Mathlevel
# We can also see the levels of "mathlevel" in the console
levels(Mathlevel$mathlevel)
# Ok, that's a lot. How much is it? Let's count the total number of rows
nrow(Mathlevel)
# Let's make a frequency table using the variable "mathlevel"
mathlevel_frequency <- Mathlevel %>% count(mathlevel)
mathlevel_frequency # View the table in the console. "n" is the number of observations
View(mathlevel_frequency) # View the table in a data window
flextable(mathlevel_frequency) # A pretty table that can be exported as a picture
barplot(mathlevel_frequency)
barplot(mathlevel_frequency$n)
?barplot
library(ggplot2)
#install.packages("dplyr")
#install.packages("Ecdat")
#install.packages("psych")
install.packages(ggplot2)
#install.packages("dplyr")
#install.packages("Ecdat")
#install.packages("psych")
install.packages("ggplot2")
library(ggplot2)
ggplot(mathlevel_frequency)
ggplot(mathlevel_frequency)
ggplot(mathlevel_frequency) + geom_histogram()
?ggplot
ggplot(mathlevel_frequency) + geom_bar()
ggplot(mathlevel_frequency, mapping = (x = mathlevel)) + geom_histogram()
ggplot(mathlevel_frequency, mapping = (x = mathlevel_frequency$mathlevel)) + geom_histogram()
ggplot(mathlevel_frequency, mapping = aes(x = mathlevel_frequency$mathlevel)) + geom_histogram()
ggplot(mathlevel_frequency, mapping = aes(x = mathlevel)) + geom_histogram()
ggplot(mathlevel_frequency, mapping = aes(x = mathlevel)) + geom_bar()
ggplot(mathlevel_frequency, mapping = aes(x = mathlevel, y = n)) + geom_bar()
ggplot(data = mathlevel_frequency, mapping = aes(x = mathlevel)) + geom_bar()
mathlevel_frequency
ggplot(data = mathlevel_frequency, mapping = aes(x = n)) + geom_bar()
ggplot(data = Mathlevel, mapping = aes(x = mathlevel)) + geom_bar()
ggplot(data = Mathlevel, mapping = aes(x = mathlevel)) + geom_polygon()
ggplot(data = Mathlevel, mapping = aes(x = mathlevel)) + geom_freqpoly()
ggplot(data = Mathlevel, mapping = aes(x = mathlevel)) + geom_bar()
ggplot(data = Mathlevel, mapping = aes(x = sex)) + geom_bar()
ggplot(data = Mathlevel, mapping = aes(x = major)) + geom_bar()
ggplot(data = Mathlevel, mapping = aes(x = chem)) + geom_bar()
head(Mathlevel)
ggplot(data = Mathlevel, mapping = aes(x = chemistcourse)) + geom_bar()
ggplot(data = Mathlevel, mapping = aes(x = mathlevel)) + geom_bar()
# Let's visualize this as a frequency polygon
ggplot(data = Mathlevel, mapping = aes(x = sat)) + geom_freqpoly()
?ggplot
? geom_freqpoly
# Let's visualize this as a frequency polygon
ggplot(data = Mathlevel, mapping = aes(x = sat)) + geom_freqpoly(binwidth = 50)
library(dplyr)
library(psych)
library(flextable)
library(ggplot2)
# First, we will save the data as a variable in RStudio
data("msq")
# Let's learn what kind of data this is
?msq
View(msq)
head(msq)
type(msq$active)
msq$active
# How many rows are in this dataset?
nrow(Mathlevel)
# How many rows are in this dataset?
nrow(msq)
# Make a frequency table using the variable "anxious"
anxious_frequency <- msq %>% count(anxious)
anxious_frequency # View the table in the console. "n" is the number of observations
View(anxious_frequency) # View the table in a data window
flextable(anxious_frequency) # A pretty table that can be exported as a picture
# Make a frequency table using the variable "anxious"
anxious_frequency <- msq %>% count(sad)
anxious_frequency # View the table in the console. "n" is the number of observations
View(anxious_frequency) # View the table in a data window
# Make a frequency table using the variable "sad"
sad_frequency <- msq %>% count(sad)
sad_frequency # View the table in the console. "n" is the number of observations
View(sad_frequency) # View the table in a data window
flextable(sad_frequency) # A pretty table that can be exported as a picture
sad_frequency$sad <- c("Not at all", "A little", "Moderately", "Very Much", "NA")
flextable(sad_frequency) # A pretty table that can be exported as a picture
# Let's visualize this with a barplot:
ggplot(data = sad_frequency, mapping = aes(x = sad)) + geom_bar()
# Let's visualize this with a barplot:
ggplot(data = msq, mapping = aes(x = sad)) + geom_bar()
# Let's visualize this with a barplot:
ggplot(data = msq, mapping = aes(x = sad), na.exclude()) + geom_bar()
# Make a frequency table using the variable "sad"
sad_frequency <- msq %>% count(happy)
sad_frequency # View the table in the console. "n" is the number of observations
# Make a frequency table using the variable "happy"
happy_frequency <- msq %>% count(happy)
happy_frequency # View the table in the console. "n" is the number of observations
flextable(happy_frequency) # A pretty table that can be exported as a picture
# The numeric scale won't mean much to readers. Change the column "sad" to a vector of strings (explain)
happy_frequency$happy <- c("Not at all", "A little", "Moderately", "Very Much", "NA")
flextable(happy_frequency) # A pretty table that can be exported as a picture
flextable(happy_frequency) # A pretty table that can be exported as a picture
1228 + 380
# Let's visualize this with a barplot:
ggplot(data = msq, mapping = aes(x = happy), na.) + geom_bar()
View(msq)
msq$Neuroticism
# Now let's try the same thing with the variable "sat"
sat_frequency <- msq %>% count(Neuroticism)
sat_frequency # View the table in the console. "n" is the number of observations
# That is too many rows! We will need to create a grouped frequency table.
# First, find the maximum and minimum
Neuroticism_sat <- min(msq$Neuroticism)
Neuroticism_sat <- max(msq$Neuroticism)
# Now, lets create variable for the Neuroticism interval size.
Neuroticism_interval_size <- 5
# Using this information we can set "breaks" for the intervals
# then cut our continuous data into "class_intervals".
breaks <- seq(min_Neuroticism, max_Neuroticism + Neuroticism_interval_size, by = Neuroticism_interval_size)
# That is too many rows! We will need to create a grouped frequency table.
# First, find the maximum and minimum
min_Neuroticism <- min(msq$Neuroticism)
max_Neuroticism <- max(msq$Neuroticism)
# Now, lets create variable for the Neuroticism interval size.
Neuroticism_interval_size <- 5
# Using this information we can set "breaks" for the intervals
# then cut our continuous data into "class_intervals".
breaks <- seq(min_Neuroticism, max_Neuroticism + Neuroticism_interval_size, by = Neuroticism_interval_size)
Neuroticism_frequency <- msq %>% group_by(sat = cut(msq$Neuroticism, breaks,right = FALSE)) %>% count()
max_Neuroticism
# That is too many rows! We will need to create a grouped frequency table.
# First, find the maximum and minimum
min_Neuroticism <- min(msq$Neuroticism, na.omit())
max_Neuroticism <- max(msq$Neuroticism, na.omit())
# Now, lets create variable for the Neuroticism interval size.
Neuroticism_interval_size <- 5
# Using this information we can set "breaks" for the intervals
# then cut our continuous data into "class_intervals".
breaks <- seq(min_Neuroticism, max_Neuroticism + Neuroticism_interval_size, by = Neuroticism_interval_size)
max_Neuroticism
# That is too many rows! We will need to create a grouped frequency table.
# First, find the maximum and minimum
min_Neuroticism <- min(msq$Neuroticism, na.omit())
max_Neuroticism <- max(msq$Neuroticism, na.omit())
# That is too many rows! We will need to create a grouped frequency table.
# First, find the maximum and minimum
min_Neuroticism <- min(msq$Neuroticism, na.omit())
# First, we will save the data as a variable in RStudio
data("msq")
# That is too many rows! We will need to create a grouped frequency table.
# First, find the maximum and minimum
min_Neuroticism <- min(msq$Neuroticism, na.omit())
# Let's visualize this with a barplot:
ggplot(data = msq, mapping = aes(x = happy), na.) + geom_bar()
# Now let's try the same thing with the variable "Neuroticism"
Neuroticism_frequency <- msq %>% count(Neuroticism)
Neuroticism_frequency # View the table in the console. "n" is the number of observations
# That is too many rows! We will need to create a grouped frequency table.
# First, find the maximum and minimum
min_Neuroticism <- min(msq$Neuroticism, na.omit())
# That is too many rows! We will need to create a grouped frequency table.
# First, find the maximum and minimum
min_Neuroticism <- min(msq$Neuroticism)
# That is too many rows! We will need to create a grouped frequency table.
# First, find the maximum and minimum
min_Neuroticism <- min(msq$Neuroticism, na.rm = TRUE)
max_Neuroticism <- max(msq$Neuroticism, na.r, = TRUE)
max_Neuroticism <- max(msq$Neuroticism, na.rm = TRUE)
# Now, lets create variable for the Neuroticism interval size.
Neuroticism_interval_size <- 5
# Using this information we can set "breaks" for the intervals
# then cut our continuous data into "class_intervals".
breaks <- seq(min_Neuroticism, max_Neuroticism + Neuroticism_interval_size, by = Neuroticism_interval_size)
Neuroticism_frequency <- msq %>% group_by(sat = cut(msq$Neuroticism, breaks,right = FALSE)) %>% count()
flextable(Neuroticism_frequency) # pretty table
# Let's visualize this as a frequency polygon
ggplot(data = Mathlevel, mapping = aes(x = sat)) + geom_freqpoly(binwidth = Neuroticism_interval_size)
# Using this information we can set "breaks" for the intervals
# then cut our continuous data into "class_intervals".
breaks <- seq(min_Neuroticism, max_Neuroticism + Neuroticism_interval_size, by = Neuroticism_interval_size)
Neuroticism_frequency <- msq %>% group_by(Neuroticism = cut(msq$Neuroticism, breaks,right = FALSE)) %>% count()
flextable(Neuroticism_frequency) # pretty table
# Let's visualize this as a frequency polygon
ggplot(data = msq, mapping = aes(x =Neuroticism )) + geom_freqpoly(binwidth = Neuroticism_interval_size)
# Let's visualize this as a histogram
ggplot(data = msq, mapping = aes(x =Neuroticism )) + geom_histogram(binwidth = Neuroticism_interval_size)
# Let's visualize this as a frequency polygon
ggplot(data = msq, mapping = aes(x =Neuroticism )) + geom_freqpoly(binwidth = Neuroticism_interval_size, na.rm = TRUE)
# Let's visualize this as a histogram
ggplot(data = msq, mapping = aes(x =Neuroticism )) + geom_histogram(binwidth = Neuroticism_interval_size, na.rm = TRUE)
plot(msq$Sociability, msq$Impulsivity)
?geom_line
data("Treatment")
Head(Treatment)
head(Treatment)
?Treatment
library(Edcat)
# Let's learn what kind of data this is
?Treatment
data("incomeInequality")
head(incomeInequality)
?incomeInequality
ggplot(data = incomeInequality, mapping = aes(x = Year, y=P99.9 )) + geom_line()
# Let's learn what kind of data this is
?incomeInequality
ggplot(data = incomeInequality, mapping = aes(x = Year, y=personsPerFamily )) + geom_line()
ggplot(data = incomeInequality, mapping = aes(x = Year, y=mean.median )) + geom_line()
ggplot(data = incomeInequality, mapping = aes(x = Year, y=realGDPperFamily )) + geom_line()
ggplot(data = incomeInequality, mapping = aes(x = Year, y=median )) + geom_line()
# Use a line plot to show realGDPperFamily by year
ggplot(data = incomeInequality, mapping = aes(x = Year, y=realGDPperFamily )) + geom_line()
# What is the maximum realGDPperFamily?
max(incomeInequality$realGDPperFamily)
incomeInequality$realGDPperFamily
# Use a line plot to show mean.median by year
ggplot(data = incomeInequality, mapping = aes(x = Year, y=mean.median )) + geom_line()
# What is the maximum realGDPperFamily?
max(incomeInequality$mean.median)
data("Hedonic")
head(Hedonic)
data("Airline")
head(Airline)
#install.packages("dplyr","Ecdat","psych","ggplot2")
install.packages("dplyr","Ecdat","psych","ggplot2")
library(dplyr)
library(Ecdat)
library(flextable)
library(ggplot2)
library(AnnotationD)
# Let's learn what kind of data this is
?Mathlevel
install.packages()
levels(Mathlevel$mathlevel)
# Ok, that's a lot. How much is it? Let's count the total number of rows
nrow(Mathlevel)
# Let's make a frequency table using the variable "mathlevel"
mathlevel_frequency <- Mathlevel %>% count(mathlevel)
mathlevel_frequency # View the table in the console. "n" is the number of observations
flextable(mathlevel_frequency) # A pretty table that can be exported as a picture
# Let's learn what kind of data this is
?Mathlevel
# Let's find the mean SAT score:
mean(Mathlevel$sat)
# Let's find the median SAT score:
median(Mathlevel$sat)
?median
# Let's find the median SAT score:
median(Mathlevel$sat, na.rm = TRUE)
# Let's find the mode SAT score:
mode(Mathlevel$sat)
?mode
i <- sort(table(Math$sat))
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# Let's find the mode SAT score:
Mode(Mathlevel$sat)
i <- unique(Mathlevel$sat)
i
match(Mathlevel$sat)
match(Mathlevel$sat, i)
plot(density(Mathlevel$sat))
Mathlevel$sat
tabulate(match(Mathlevel$sat, i))
i <- unique(Mathlevel$sat)
i
# Finding the mode is a bit harder.
# Sadly mode(x) doesn't work.
# Let's create our own function.
# First, we can find all of the unique values
uni <- unique(Mathlevel$sat)
# All of the values in uni have a unique index. For instance:
uni[1]
uni[2]
uni[1] == uni[2]
tabulate(Mathlevel$sat)
i[which.max(tabulate(match(Mathlevel$sat, i)))]
# Let's find the median SAT score:
median(Mathlevel$sat, na.rm = TRUE).
# Finding the mode is a bit harder.
# Sadly mode(x) doesn't work.
# Let's create our own function.
# First, we can find all of the unique values
uni <- unique(Mathlevel$sat)
# This next function finds the how many times each value shows up and picks the largest
uni[which.max(tabulate(match(Mathlevel$sat, uni)))]
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Mathlevel$sat))
?plot
?density
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Mathlevel$sat), title("Density of SAT scores"))
?plot
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Mathlevel$sat), main = "Density of SAT scores")
# First, we will save the data as a variable in RStudio
data("incomeInequality")
head(incomeInequality)
# Let's learn what kind of data this is
?Treatment
mean(Treatment)
mean(Treatment$age, na.rm = TRUE)
mean(Treatment$education, na.rm = TRUE)
Treatment$educ
median(Treatment$education, na.rm = TRUE)
mean(Treatment$re75, na.rm = TRUE)
mean(Treatment$re74, na.rm = TRUE)
mean(Treatment$re78, na.rm = TRUE)
mean(Treatment$u78, na.rm = TRUE)
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Mathlevel$sat))
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Treatment$age))
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Treatment$re75))
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Treatment$re76))
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Treatment$re74))
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Treatment$re78))
# What is the average age of participants
mean(Treatment$age)
Mode <- function(x) {
uni <- unique(x)
ux[which.max(tabulate(match(x, uni)))]
}
# What is the mode age of participants
Mode(Treatment$age)
# Now let's try the same thing with the variable "sat"
sat_frequency <- Mathlevel %>% count(sat)
library(dplyr)
library(Ecdat)
library(flextable)
library(ggplot2)
# First, we will save the data as a variable in RStudio
data("Mathlevel")
# Let's learn what kind of data this is
?Mathlevel
# Now let's try the same thing with the variable "sat"
sat_frequency <- Mathlevel %>% count(sat)
sat_frequency # View the table in the console. "n" is the number of observations
library(dplyr)
library(Ecdat)
library(flextable)
library(ggplot2)
# First, we will save the data as a variable in RStudio
data("Mathlevel")
# Let's learn what kind of data this is
?Mathlevel
# Let's find the mean SAT score:
mean(Mathlevel$sat, na.rm = TRUE)
# Let's find the median SAT score:
median(Mathlevel$sat, na.rm = TRUE)
# Finding the mode is a bit harder.
# Sadly mode(x) doesn't work.
# Let's create our own function.
# First, we can find all of the unique values
uni <- unique(Mathlevel$sat)
# This next function finds the how many times each value shows up and picks the largest
uni[which.max(tabulate(match(Mathlevel$sat, uni)))]
# Rather than calling these two complicated functions every time we want to find a mean,
# let's make a function. Note that the variable Mathlevel$sat is replaced with x
Mode <- function(x) {
uni <- unique(x)
uni[which.max(tabulate(match(x, uni)))]
}
# Let's find the mode SAT score using our new function!
Mode(Mathlevel$sat)
# Now that we have the measures of central tendency, let's view the density plot.
plot(density(Mathlevel$sat), main = "Density of SAT scores")
?density
mode(Mathlevel$sat)
unique(Mathlevel$sat)
?boxplot
sat_box <- boxplot(Mathlevel$sat)
sat_box
?box
?boxplot
sat_box <- boxplot(Mathlevel$sat)
sat_box
library(dplyr)
library(Ecdat)
library(flextable)
library(ggplot2)
# First, we will save the data as a variable in RStudio
data("Mathlevel")
sat_box <- boxplot(Mathlevel$sat)
sat_box
?boxplot
sat_box$out
# The IQR is just
sat_IQR <- sat_box$stats[4] - sat_box$stats[2]
sat_IQR
# Now let's find the range of values
range(Mathlevel$sat)
range_sat <- min_max_sat[1] - min_max_sat[0]
# Now let's find the range of values
min_max_sat <- range(Mathlevel$sat)
range_sat <- min_max_sat[1] - min_max_sat[0]
range_sat
range_sat <- min_max_sat[2] - min_max_sat[1]
range_sat <- min_max_sat[2] - min_max_sat[1]
range_sat
# Now let's find the range of values
range_sat <- max(Mathlevel$sat) - min(Mathlevel$sat)
range_sat
# Let's find the standard deviations
summary(Mathlevel$sat)
# Let's find the standard deviations
?var
# Let's find the standard deviations
?stdev
# Let's find the standard deviations
summaryRprof(Mathlevel$sat)
library(dplyr)
library(Ecdat)
library(flextable)
library(ggplot2)
# First, we will save the data as a variable in RStudio
data("Mathlevel")
# Let's make a boxplot with the data
sat_box <- boxplot(Mathlevel$sat)
sat_box
# Now let's find the range of values
range_sat <- max(Mathlevel$sat) - min(Mathlevel$sat)
# Look at the Help box, and scroll down to the Value section.
?boxplot
# Let's look at the Quartile values
summary(Mathlevel$sat)
# The IQR is just
sat_IQR <- sat_box$stats[4] - sat_box$stats[2]
# We can also get a list of all of the outlier values
sat_box$out
# Let's find the standard deviations
sd(Mathlevel$sat)
?sd
# Let's find the variance
var(Mathlevel$sat)
sat_IQR
IQR(Mathlevel$sat)
# First, let's get the minimum and maximum values
sat_range <- range(Mathlevel$sat)
# Now, we will find the difference between the minimum and maximum values
diff(sat_range)
# Now let's find the range of values
range_sat <- max(Mathlevel$sat) - min(Mathlevel$sat)
range_sat
?var
# Let's find the variance
var(Mathlevel$sat)
# Let's find the variance
sqrt(var(Mathlevel$sat))
# Let's find the standard deviations
sd(Mathlevel$sat)
sd?
# Let's find the standard deviations
sd(Mathlevel$sat)
?sd
d(1:2) ^ 2
ad(1:2) ^ 2
sd(1:2) ^ 2
library(dplyr)
library(Ecdat)
library(flextable)
library(ggplot2)
# First, we will save the data as a variable in RStudio
data("Treatment")
# What is the range of the data?
Treatment$age
# What is the range of the data?
range(Treatment$age)
# What is the the minimum and maximum age of participants? What is the difference?
age_range <- range(Treatment$age)
diff(age)
# What is the IQR of the age of participants?
IQR(Treatment$age)
# What is the standard deviation?
sd(Treatment$age)
# What is the variance of age?
var(Treatment$age)
# What is the the minimum and maximum age of participants? What is the difference?
age_range <- range(Treatment$educ)
diff(age_range)
age_range
# What is the IQR of the age of participants?
IQR(Treatment$educ)
# What is the variance of age?
var(Treatment$educ)
# What is the standard deviation?
sd(Treatment$educ)
mean(Treatment$educ)
?Treatment
# What is the the minimum and maximum age of participants? What is the difference?
educ_range <- range(Treatment$re78)
diff(educ_range)
# What is the IQR of the age of participants?
IQR(Treatment$re78)
# What is the variance of age?
var(Treatment$re78)
# What is the standard deviation?
sd(Treatment$re78)
Treatmen$re78
Treatment$re78
